# LAM
SR networks are mysterious and little works make attempt to understand them. In this work, we perform attribution analysis of SR networks, which aims at finding the input pixels that strongly influence the SR results. We propose a novel attribution approach called local attribution map (LAM) to interpret SR networks. Our work opens new directions for designing SR networks and interpreting low-level vision deep models.

Local Attribution Maps (LAM)
 1. Interpreting local not global.
 2. Interpreting hard not simple.
 3. Interpreting features not pixels.
